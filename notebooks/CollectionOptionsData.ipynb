{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nsepython import *\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"PNB\" # Selecte the symbol for which you want to download the data according to the instructions given for selection of stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Options Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentType = \"options\"\n",
    "optionType=\"CE\"\n",
    "series = \"EQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity =pd.read_csv(\"../data/PNB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expiry_list = expiry_history(symbol,start_date=\"01-01-2012\",end_date=\"01-08-2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = [\"19-Sep-2019\",\"03-Oct-2019\",\"10-Oct-2019\",\"17-Oct-2019\",\"24-Oct-2019\",\"07-Nov-2019\",\"14-Nov-2019\",\"21-Nov-2019\",\"20-Apr-2023\",\"04-May-2023\"\n",
    "               ,\"11-May-2023\",\"18-May-2023\",\"01-Jun-2023\",\"07-Sep-2023\",\"14-Sep-2023\",\"21-Sep-2023\",\"05-Oct-2023\"\n",
    "               ,\"12-Oct-2023\",\"19-Oct-2023\"]\n",
    "\n",
    "# I'm removing these entries as they appear to be weekly expiries mistakenly categorized as monthly expiries. \n",
    "# This misclassification hinders data collection, as the current package and other data sources provided only \n",
    "# support historical option data on a daily basis\n",
    "for i in remove_list:\n",
    "    try:\n",
    "        expiry_list.remove(i)\n",
    "    except:\n",
    "        print(\"Error in removing\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/CSV/\"\n",
    "# Options Data is from 01-Jan-2015 to 25-Apr-2024\n",
    "for i in range(149,35,-1):\n",
    "        continues_empty = 0\n",
    "\n",
    "        # Getting Start and End Date for a selected expiry\n",
    "        start_date = datetime.datetime.strptime(expiry_list[i-1], '%d-%b-%Y')\n",
    "        start_date += datetime.timedelta(days=1)\n",
    "        start_date = start_date.strftime('%d-%m-%Y')\n",
    "        end_date = datetime.datetime.strptime(expiry_list[i], '%d-%b-%Y')\n",
    "        end_date += datetime.timedelta(days=1)\n",
    "        end_date = end_date.strftime('%d-%m-%Y')\n",
    "        expiry_date = expiry_list[i]\n",
    "        \n",
    "        # Step 1: Get the stock price of the start date to decide the range of strike prices\n",
    "        price = list(equity[equity['Date&Time'] == start_date]['Close'])\n",
    "        temp_date = datetime.datetime.strptime(start_date, '%d-%m-%Y')\n",
    "        while len(price) == 0:\n",
    "            temp_date += datetime.timedelta(days=1)\n",
    "            price = list(equity[equity['Date&Time'] == temp_date.strftime('%Y-%m-%d') ]['Close'])\n",
    "            \n",
    "        # fixing the range of stike prices to check +200,-200 is an approximation we can still decrease the range\n",
    "        price = int(price[0]/40)*40\n",
    "        start_price = int((price-200)/40)*40\n",
    "        end_price = int((price+200)/40)*40\n",
    "        if start_price < 0:\n",
    "            start_price = 0\n",
    "        strike_price_wise = {}\n",
    "        \n",
    "        # Step 2: Iterate over each strike price with a step of 5 . decided 5 after checking certain strike prices for different Expiry Dates.\n",
    "        for j in range(start_price,end_price,5):\n",
    "            x = derivative_history(symbol,start_date,end_date,instrumentType,expiry_date,j,optionType)\n",
    "            if x.empty:\n",
    "                # consider only 10 continuous empty strike prices after strike price is greater than price to reduce the number strike price data to collect as rest after will also be empty\n",
    "                if j > price:  # Only increment if j is greater than price, as per your logic\n",
    "                    continues_empty += 1\n",
    "                if continues_empty > 10:\n",
    "                    break\n",
    "            else:\n",
    "                continues_empty = 0  # Reset if x is not empty\n",
    "\n",
    "            if not x.empty:\n",
    "                strike_price_wise[j] = x\n",
    "            \n",
    "        # Step 3: Converting the strike_price_wise dictionary to Date wise csv for model to take a look at the current Option Chain of a date\n",
    "        if len(strike_price_wise) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            unique_dates = []\n",
    "            for key in strike_price_wise.keys():\n",
    "                unique_dates += list(strike_price_wise[key]['FH_TIMESTAMP'].unique())\n",
    "            unique_dates = list(set(unique_dates))\n",
    "            datewise_consolidated_dfs = {}\n",
    "            \n",
    "\n",
    "            # Iterate over each unique date and Create a DataFrame for each date with all the strike prices\n",
    "            for date in unique_dates:\n",
    "                temp_data = []\n",
    "\n",
    "                #Iterate over each strike price and its DataFrame\n",
    "                for strike_price, df in strike_price_wise.items():\n",
    "                    filtered_df = df[df['FH_TIMESTAMP'] == date]\n",
    "                    temp_data.append(filtered_df)\n",
    "\n",
    "                # Combine and drop unnecessary columns during concatenation\n",
    "                consolidated_df = pd.concat(temp_data, ignore_index=True)\n",
    "                columns_to_drop = ['_id', 'FH_INSTRUMENT', 'FH_SYMBOL', 'FH_MARKET_TYPE', 'FH_UNDERLYING_VALUE', 'TIMESTAMP']\n",
    "                consolidated_df.drop(columns=columns_to_drop, inplace=True)\n",
    "                datewise_consolidated_dfs[date] = consolidated_df\n",
    "                \n",
    "                \n",
    "            for x,y in datewise_consolidated_dfs.items():\n",
    "                y.to_csv(f\"{path}{x}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exception Handling: Updating URL in `derivative_history`\n",
    "\n",
    "In case of an error with the `derivative_history` function , perform the following steps to ensure correct data fetching:\n",
    "\n",
    "1. **Identify the Function**: Navigate to the definition of the `derivative_history` function in the source code.\n",
    "2. **Backup Function**: Locate the `derivative_history_virgin` function within the same source code file.\n",
    "3. **Update the URL**: Modify the `nsefetch_url` variable by changing the base URL to:\n",
    "   ```python\n",
    "   \"https://www.nseindia.com/api/historical/foCPV?&from=\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Option Data Collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/CSV/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file[12:] for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file.split('.')[0] for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [datetime.datetime.strptime(file, '%d-%b-%Y') for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.sort()\n",
    "files = [file.strftime('%d-%b-%Y') for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/PNB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(745,3050):\n",
    "    x = df['Date&Time'][i]\n",
    "    y = datetime.datetime.strptime(x, '%Y-%m-%d').strftime('%d-%b-%Y')\n",
    "    if y not in files:\n",
    "        print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

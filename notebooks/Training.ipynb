{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.trading_env_final import TradingEnv\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/PNB_Indicators.csv\")\n",
    "df_option_data = pd.read_csv(\"../data/PNB_Options_Data.csv\")\n",
    "\n",
    "options_path = \"../data/CSV\" # has date realted to options on each day\n",
    "\n",
    "window_size = 10\n",
    "start_index = 748 # 2015-01-01\n",
    "end_index = 2723 # 2022-12-30\n",
    "frame_bound = (start_index, end_index)\n",
    "margin = 1000000000\n",
    "lot_size = 1000\n",
    "spread = 5 # no.of stikes from atm to consider as itm and otm\n",
    "\n",
    "env = TradingEnv(df, df_option_data, window_size, frame_bound, margin, lot_size, spread, options_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,t1 = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env)\n",
    "t,t1 = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This values are to be filled after hyperparameter tuning if not just run withuot passing these values\n",
    "learning_rate = 0.0005367590641575743\n",
    "gamma = 0.9315531162894451\n",
    "gae_lambda = 0.9210798936175724\n",
    "n_steps = 5\n",
    "entropy_coef = 0.049835574208271116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(\"MlpPolicy\", env, verbose=1,\n",
    "                learning_rate=learning_rate,\n",
    "                gamma=gamma,\n",
    "                gae_lambda=gae_lambda,\n",
    "                n_steps=n_steps,\n",
    "                ent_coef=entropy_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000) # 98750 for 50 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../Model/a2c_trading_env2_spread5_final\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_path1 = \"../data/CSV\" \n",
    "frame_bound=(2725, 3040) #2023-01-02 to 2024-04-10\n",
    "speread = 5\n",
    "new_env = TradingEnv(df, df_option_data, window_size, frame_bound, margin, lot_size, spread, options_path)\n",
    "new_env = DummyVecEnv([lambda: new_env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../Model/a2c_trading_env2_spread5_final\"\n",
    "loaded_model = A2C.load(model_path)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = new_env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _states = loaded_model.predict(obs)\n",
    "    obs, rewards, done, info = new_env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info[0]['total_profit'])\n",
    "print(info[0]['total_reward'])\n",
    "print(info[0]['drawdown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
